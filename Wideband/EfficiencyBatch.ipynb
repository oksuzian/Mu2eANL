{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_data = \"rec.mu2e.CRV_wideband_cosmics.CRVWB-000-006-000-012.root\"\n",
    "DATASET_mc_v5 = \"nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v5.root\"\n",
    "DATASET_mc_v2 = \"nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v2.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oHf6HNtWTywN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from mu2etools import *\n",
    "from mu2etools import wideband\n",
    "hep.style.use('ATLAS')  # or ATLAS/LHCb2\n",
    "import hist\n",
    "from hist import Hist\n",
    "import mplhep as mplhep\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: root://fndcadoor.fnal.gov:1094/mu2e/tape/phy-nts/nts/mu2e/CRV_wideband_cosmics-mc/config_0011_v2/root/ae/7d/nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v2.001002_00000000.root:CrvWidebandTest/WidebandTree\n",
      "Processing file: root://fndcadoor.fnal.gov:1094/mu2e/tape/phy-nts/nts/mu2e/CRV_wideband_cosmics-mc/config_0011_v5/root/89/69/nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v5.001005_00000003.root:CrvWidebandTest/WidebandTree\n",
      "Processing file: root://fndcadoor.fnal.gov:1094/mu2e/tape/phy-rec/rec/mu2e/CRV_wideband_cosmics-noadc/CRVWB-000-006-000/root/e9/92/rec.mu2e.CRV_wideband_cosmics-noadc.CRVWB-000-006-000.001720_000.root:run\n"
     ]
    }
   ],
   "source": [
    "processor = wideband.DataProcessor(usexroot=True, treename='CrvWidebandTest/WidebandTree')\n",
    "ar2 = processor.getEffData(\"nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v2.root\", nfiles=10, data_type=2)\n",
    "ar5 = processor.getEffData(\"nts.mu2e.CRV_wideband_cosmics-mc.config_0011_v5.root\", nfiles=10, data_type=5)\n",
    "processor = wideband.DataProcessor(usexroot=True, treename='run')\n",
    "ar_data = processor.getEffData(\"rec.mu2e.CRV_wideband_cosmics.CRVWB-000-006-000-012.root\", nfiles=10, data_type=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ar = ak.concatenate([ar2, ar5, ar_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#List of variable to export to a skimmed array\n",
    "varlist=['spillNumber', 'eventNumber','runNumber', 'subrunNumber',\n",
    "         'trackPEs', 'trackPoints', 'trackChi2', 'trackIntercept', 'trackSlope']\n",
    "\n",
    "all_layers = np.arange(0,16) \n",
    "test_layers = np.arange(2,6) # Test layers are 2 through 6\n",
    "trig_layers = all_layers[~np.isin(all_layers, test_layers)]\n",
    "varlist.extend(['nTrigHits', 'PEsTestLayers', 'PEsTrigLayers', \"mc\"])\n",
    "#varlist.extend(['PEsTestLayers'])\n",
    "\n",
    "ar_skim_list = []\n",
    "\n",
    "#filelist = filelist_mc[0:10] + filelist_data[0:1]\n",
    "filelist = filelist_mc_v5+filelist_mc_v2+filelist_data[0:5]\n",
    "for idx, filename in enumerate(filelist):\n",
    "    if idx%20 == 0:\n",
    "        print(\"Processing file: %s\"%filename)\n",
    "    file = uproot.open(filename)\n",
    "    for ar in uproot.iterate(file, step_size=\"10MB\", \n",
    "                                   filter_name=['PEs', varlist, 'coincidencePosX'], \n",
    "                                   library='ak', options={\"timeout\": 7200}):\n",
    "        # Set PEs to zero for aging and quad-counters\n",
    "        ak.to_numpy(ar['PEs'])[:,0,0:8] = 0\n",
    "        ak.to_numpy(ar['PEs'])[:,3,0:8] = 0\n",
    "        ak.to_numpy(ar['PEs'])[:,7,0:8] = 0\n",
    "                                \n",
    "        # Filter out hits below 5PE\n",
    "        ar_trig_filt = ak.where(ar['PEs'] >= 5, ar['PEs'], 0)\n",
    "        # Calculate PEs for even and odd layers\n",
    "        PEs_even_layers = ak.sum(ar_trig_filt[:, :, 0:32], axis=-1).to_numpy()\n",
    "        PEs_odd_layers = ak.sum(ar_trig_filt[:, :, 32:64], axis=-1).to_numpy()        \n",
    "        # Interleave the elements from even and odd arrays\n",
    "        PEs_interleaved = np.concatenate((PEs_even_layers[:, :, np.newaxis], PEs_odd_layers[:, :, np.newaxis]), axis=2)\n",
    "        # Reshape the interleaved array to match the desired shape\n",
    "        PEs_stacked = PEs_interleaved.reshape(-1, 16)        \n",
    "        # Add PEs for even and odd layers to the original array\n",
    "        ar['PEsAllLayer'] = PEs_stacked\n",
    "        # Count the number of triggered layers\n",
    "        ar['nTrigHits'] = ak.sum(ar['PEsAllLayer'][:, trig_layers] > 10, axis=-1)\n",
    "        # Filter out events with more than 10 triggered layers        \n",
    "        ar = ar[ar['nTrigHits'] > 8]\n",
    "        # Extract only PEsTestLayers to save memory\n",
    "        ar['PEsTestLayers'] = ar['PEsAllLayer'][:, test_layers]\n",
    "        ar['PEsTrigLayers'] = ar['PEsAllLayer'][:, trig_layers]\n",
    "        \n",
    "        pattern = re.compile(r'cosmics-mc\\.config.*_v(\\d+)')\n",
    "        match = re.search(pattern, filename)\n",
    "        \n",
    "        print(int(match.group(1)))\n",
    "        if match:\n",
    "            ar['mc'] = int(match.group(1))\n",
    "            ar['trackIntercept'] = ar['trackIntercept'] - 20950.0\n",
    "            # Mimic the trigger paddles\n",
    "            trigPad_cut = (abs(ar[\"coincidencePosX\"][:,1]+5604) < 20) & (abs(ar[\"coincidencePosX\"][:,4] + 5604) < 20)\n",
    "            ar = ar[trigPad_cut]\n",
    "        else:\n",
    "            ar['mc'] = -1\n",
    "        \n",
    "        # Append to the list\n",
    "        ar_skim_list.append(ar[varlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ar_skim = ak.concatenate(ar_skim_list, axis=0)\n",
    "# Number of layer hits in the test module\n",
    "ar_skim['nTestHits'] = ak.sum(ar_skim['PEsTestLayers'] > 10, axis=-1)\n",
    "# Chi2NDF only if denominator if > 0\n",
    "ar_skim['trackChi2NDF'] = ak.where(ar_skim['trackPoints'] > 2, ar_skim['trackChi2'] / (ar_skim['trackPoints'] - 2), -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(ar_skim[ar_skim['mc']==5]['nTrigHits'], bins=13, range=(0, 13), histtype='step', label='MC: v5', density=True);\n",
    "plt.hist(ar_skim[ar_skim['mc']==2]['nTrigHits'], bins=13, range=(0, 13), histtype='step', label='MC: v2', density=True);\n",
    "plt.hist(ar_skim[ar_skim['mc']==-1]['nTrigHits'], bins=13, range=(0, 13), histtype='step', label='Data', density=True);\n",
    "plt.xlabel('nTrigHits');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cuts\n",
    "chi2NDF_lower_limit = 0\n",
    "chi2NDF_upper_limit = 30\n",
    "\n",
    "intercept_lower_limit = -700\n",
    "intercept_upper_limit = -200\n",
    "\n",
    "#intercept_lower_limit = -520\n",
    "#intercept_upper_limit = -290\n",
    "\n",
    "trackPoints_limit = 40\n",
    "trackPEs_limit = 3000\n",
    "nTrigHits_limit = 12\n",
    "\n",
    "# Define the cut conditions\n",
    "condition_chi2 = (ar_skim[\"trackChi2NDF\"] > chi2NDF_lower_limit) & (ar_skim[\"trackChi2NDF\"] < chi2NDF_upper_limit)\n",
    "condition_intercept = (ar_skim[\"trackIntercept\"] > intercept_lower_limit) & (ar_skim[\"trackIntercept\"] < intercept_upper_limit)\n",
    "condition_trackPEs = ar_skim[\"trackPEs\"] < trackPEs_limit\n",
    "condition_nTrigHits = ar_skim[\"nTrigHits\"] >= nTrigHits_limit\n",
    "condition_trackPoints = ar_skim[\"trackPoints\"] < trackPoints_limit\n",
    "\n",
    "# Cut categories\n",
    "cut_categories = [condition_chi2, \n",
    "                  condition_chi2 & condition_intercept, \n",
    "                  condition_chi2 & condition_intercept & condition_trackPEs, \n",
    "                  condition_chi2 & condition_intercept & condition_trackPEs & condition_nTrigHits, \n",
    "                  condition_chi2 & condition_intercept & condition_trackPEs & condition_nTrigHits & condition_trackPoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create histograms\n",
    "axis1 = hist.axis.IntCategory(label='NHits', name='nhits', categories=[1, 2, 3, 4])\n",
    "axis2 = hist.axis.StrCategory(label='Cuts', name='cut', categories=[\"trackChi2\", \"intercept\", \"trackPEs\", \"nTrigHits\", \"all\"])\n",
    "axis3 = hist.axis.IntCategory(label='Data type', name='dtype', categories=[-1, 1, 2, 3, 4, 5])\n",
    "axis4 = hist.axis.IntCategory(label='NLayers', name='layer', categories=[1, 2, 3, 4])\n",
    "\n",
    "h_nTrigHits = Hist(hist.axis.Regular(6, 8, 14, name=\"nTrigHits\"), axis1, axis2, axis3)\n",
    "h_PEsTestLayers = Hist(hist.new.Reg(100, 0, 200, name=\"PEsTestLayers\"), axis1, axis2, axis3)\n",
    "h_trackChi2NDF = Hist(hist.new.Reg(100, 0, 100, name=\"trackChi2NDF\"), axis1, axis2, axis3)\n",
    "h_trackPEs = Hist(hist.new.Reg(100, 1000, 5000, name=\"trackPEs\"), axis1, axis2, axis3)\n",
    "h_trackPoints = Hist(hist.new.Reg(80, 0, 80, name=\"trackPoints\"), axis1, axis2, axis3)\n",
    "h_trackIntercept = Hist(hist.new.Reg(80, -1000, 100, name=\"trackIntercept\"), axis1, axis2, axis3)\n",
    "h_trackSlope = Hist(hist.new.Reg(80, -1, 1, name=\"trackSlope\"), axis1, axis2, axis3)\n",
    "\n",
    "h_trackPEsHit = Hist(hist.new.Reg(100, 0, 500, name=\"trackPEsHit\"), axis1, axis2, axis3)\n",
    "\n",
    "h_PEsLayer = Hist(hist.new.Reg(100, 0, 500, name=\"PEsLayer\", flow=True), axis1, axis2, axis3, axis4)\n",
    "h_PEsLayerSort = Hist(hist.new.Reg(100, 0, 500, name=\"PEsLayerSort\", flow=True), axis1, axis2, axis3, axis4)\n",
    "\n",
    "histogram_list = [h_nTrigHits, h_PEsTestLayers, h_trackChi2NDF, \n",
    "                  h_trackPEs, h_trackPoints, h_trackIntercept, h_trackSlope]\n",
    "\n",
    "# Iterate over nhits values and fill the histograms\n",
    "for data_type in axis3:\n",
    "    dtype_condition = (ar_skim[\"mc\"] == data_type)\n",
    "    for nhits in axis1:\n",
    "        hits_condition = ar_skim['nTestHits'] <= nhits\n",
    "        for idx, cut in enumerate(axis2):\n",
    "\n",
    "            cut_condition = cut_categories[idx] & hits_condition & dtype_condition\n",
    "\n",
    "            for histogram in histogram_list:\n",
    "                var_name = histogram.axes[0].label\n",
    "                if(var_name == \"PEsTestLayers\"):\n",
    "                    arr_fill = ak.flatten(ar_skim[cut_condition][var_name])\n",
    "                else:\n",
    "                    arr_fill = ar_skim[cut_condition][var_name]\n",
    "                histogram.fill(arr_fill, nhits=nhits, cut=cut, dtype=data_type)\n",
    "\n",
    "            h_trackPEsHit.fill(ar_skim[cut_condition]['trackPEs']/ar_skim[cut_condition]['trackPoints'], nhits=nhits, cut=cut, dtype=data_type)\n",
    "\n",
    "            for layer in axis4:\n",
    "                h_PEsLayer.fill(ar_skim[cut_condition]['PEsTestLayers'][:,layer-1], nhits=nhits, cut=cut, dtype=data_type, layer=layer)\n",
    "                h_PEsLayerSort.fill(ak.sort(ar_skim[cut_condition]['PEsTestLayers'], axis=1)[:,layer-1], nhits=nhits, cut=cut, dtype=data_type, layer=layer)\n",
    "\n",
    "histogram_list.extend([h_trackPEsHit, h_PEsLayerSort, h_PEsLayer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in range(0,4):\n",
    "    plt.figure()\n",
    "    h_PEsLayerSort[:, 3, \"all\", 2, layer].plot(flow=\"sum\", label='Layer %d: MC-v2'%layer, density=True)\n",
    "    h_PEsLayerSort[:, 3, \"all\", 5, layer].plot(flow=\"sum\", label='Layer %d: MC-v5'%layer, density=True)\n",
    "    h_PEsLayerSort[:, 3, \"all\", 0, layer].plot(flow=\"sum\", label='Layer %d: Data'%layer, density=True)\n",
    "#    plt.yscale('log');\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"PEsLayerSort\")\n",
    "    plt.xlim(0,300)\n",
    "\n",
    "for layer in range(0,4):\n",
    "    plt.figure()\n",
    "    h_PEsLayer[:, 3, \"all\", 2, layer].plot(flow=\"sum\", label='Layer %d: MC-v2'%layer, density=True)\n",
    "    h_PEsLayer[:, 3, \"all\", 5, layer].plot(flow=\"sum\", label='Layer %d: MC-v5'%layer, density=True)\n",
    "    h_PEsLayer[:, 3, \"all\", 0, layer].plot(flow=\"sum\", label='Layer %d: Data'%layer, density=True)\n",
    "#    plt.yscale('log');\n",
    "    plt.xlabel(\"PEsLayer\")\n",
    "    plt.legend()    \n",
    "#    plt.xlim(0,300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_extrapolated_efficiency(cut, data_type, nfold):\n",
    "    h = h_PEsLayer[:, 3, cut, data_type, :]\n",
    "    # Normalize histogram to unity\n",
    "    normalized_hist = np.mean(h, axis=1) / np.mean(h, axis=1).sum()\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = np.cumsum(normalized_hist)\n",
    "    cdf = binom.cdf(3-nfold, 4, 1 - cdf)\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_efficiency(nfold, ismc):\n",
    "\n",
    "    h = h_PEsLayerSort[:, 3, \"intercept\", ismc, nfold]\n",
    "    # Normalize histogram to unity\n",
    "    normalized_hist = h.values() / h.sum(flow=True)\n",
    "\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = np.cumsum(normalized_hist)\n",
    "    cdf = np.clip(cdf, 1e-10, 1 - 1e-10)\n",
    "\n",
    "    # Calculate the error bars for the CDF\n",
    "    error_cdf = np.sqrt(cdf * (1 - cdf) / h.sum(flow=True))\n",
    "\n",
    "    # Plot the normalized histogram and CDF with error bars on the same axis\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    # Plot the second lowest PEs\n",
    "    mplhep.histplot(h, ax=ax1, label='PEs layer: sorted', flow=\"sum\")\n",
    "    # Create a second y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.fill_between(h.axes[0].centers, cdf - error_cdf, cdf + error_cdf, color='red', alpha=0.2, label='Meas. %d/4 inefficiency'%(4-nfold))\n",
    "    ax2.plot(h.axes[0].centers, cdf, 'r-', linewidth=0.5)\n",
    "\n",
    "    cdf_est = get_extrapolated_efficiency(\"all\", ismc, nfold)\n",
    "    ax2.plot(h.axes[0].centers, cdf_est, 'b-', alpha=0.7, label='Extrap. %d/4 inefficiency'%(4-nfold))\n",
    "\n",
    "    # Set labels for both y-axes\n",
    "    ax1.set_ylabel('Counts', color='blue')\n",
    "    ax2.set_ylabel('Cumulative Probability', color='red')\n",
    "    \n",
    "    ax2.axhline(y=1E-4, color='red', linestyle='--', label='CRV requirement', linewidth=1)\n",
    "\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    ax2.set_yscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    plt.xlim(0, 200);\n",
    "    plt.ylim(1E-6, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for nfold in range(0,4):\n",
    "    plt.figure()\n",
    "    plot_efficiency(nfold, True);\n",
    "    plt.title(\"MC\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_efficiency(nfold, False);\n",
    "    plt.title(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_cuts = cut_categories[4] & (abs(ar_skim[\"trackSlope\"]) < 0.1)\n",
    "# Extract arrays from data and MC samples\n",
    "data_layer = ar_skim[base_cuts & ~ar_skim[\"mc\"]]['PEsTestLayers']\n",
    "mc_layer = ar_skim[base_cuts & ar_skim[\"mc\"]]['PEsTestLayers']\n",
    "\n",
    "plt.hist(ak.sort(data_layer, axis=1)[:,1], bins=20, range=(50, 200), histtype='step', density=True, label='Data');\n",
    "plt.hist(ak.sort(mc_layer, axis=1)[:,1], bins=20, range=(50, 200), histtype='step', density=True, label='MC');\n",
    "plt.legend();\n",
    "plt.xlabel('PEs in the 2nd lowest layer')\n",
    "\n",
    "for layer in range(0,4):\n",
    "    plt.figure()\n",
    "    plt.hist(data_layer[:,layer], bins=20, range=(50, 200), histtype='step', density=True, label='Data');\n",
    "    plt.hist(mc_layer[:,layer], bins=20, range=(50, 200), histtype='step', density=True, label='MC');\n",
    "    plt.legend();\n",
    "    plt.xlabel('PEs in layer %d'%layer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Just a cross-check\n",
    "\n",
    "# Plot MC\n",
    "plot_efficiency(1, False);\n",
    "\n",
    "#Plot Data\n",
    "h, edges = np.histogram(ak.sort(ar_skim[cut_categories[1] & (~ar_skim[\"mc\"])]['PEsTestLayers'], axis=1)[:,1].to_numpy(), bins=1000, range=(0, 2000))\n",
    "cumulative = np.cumsum(h).astype(float)  # Convert to float\n",
    "cumulative /= cumulative[-1]\n",
    "plt.plot(edges[:-1], cumulative, \"--g\", label='Data')\n",
    "plt.legend()\n",
    "plt.yscale('log');\n",
    "plt.xlim(0,140);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = h_PEsLayerSort[:, 3, \"all\", True, 1]\n",
    "cdf_est = get_extrapolated_efficiency(\"all\", True, 1)\n",
    "plt.plot(h.axes[0].centers, cdf_est, 'b-', alpha=0.7, label='Extr. 3/4 inefficiency: MC')\n",
    "plt.yscale('log');\n",
    "plt.xlim(0,140);\n",
    "\n",
    "h = h_PEsLayerSort[:, 3, \"all\", False, 1]\n",
    "cdf_est = get_extrapolated_efficiency(\"all\", False, 1)\n",
    "plt.plot(h.axes[0].centers, cdf_est, 'g-', alpha=0.7, label='Extrap. 3/4 inefficiency: Data')\n",
    "plt.yscale('log');\n",
    "plt.xlim(0,140);\n",
    "plt.legend()\n",
    "\n",
    "#Plot MC\n",
    "h, edges = np.histogram(ak.sort(ar_skim[cut_categories[4] & (ar_skim[\"mc\"])]['PEsTestLayers'], axis=1)[:,1].to_numpy(), bins=1000, range=(0, 2000))\n",
    "cumulative = np.cumsum(h).astype(float)  # Convert to float\n",
    "cumulative /= cumulative[-1]\n",
    "plt.plot(edges[:-1], cumulative, '--', color='orange',  label='Meas. 3/4: MC')\n",
    "plt.legend()\n",
    "plt.yscale('log');\n",
    "plt.xlim(0,140);\n",
    "\n",
    "#Plot Data\n",
    "h, edges = np.histogram(ak.sort(ar_skim[cut_categories[4] & (~ar_skim[\"mc\"])]['PEsTestLayers'], axis=1)[:,1].to_numpy(), bins=100, range=(0, 200))\n",
    "cumulative = np.cumsum(h).astype(float)  # Convert to float\n",
    "cumulative /= cumulative[-1]\n",
    "plt.plot(edges[:-1], cumulative, \"r--\", label='Meas. 3/4: Data')\n",
    "plt.legend()\n",
    "plt.yscale('log');\n",
    "plt.xlim(0,140);\n",
    "\n",
    "plt.xlabel('Threshold [PEs]')\n",
    "\n",
    "\n",
    "ex_eff_tyler=[8.42576148e-06, 1.45093773e-05, 4.81819494e-05, 1.40458939e-04,\n",
    " 5.39816619e-04, 2.53147644e-03, 1.80419720e-02, 1.07752884e-01,\n",
    " 3.61844511e-01, 6.86125430e-01, 8.78211946e-01, 9.52824329e-01,\n",
    " 9.78828587e-01,]\n",
    "meas_eff_tyler=[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 1.84094256e-04, 1.28865979e-03, 1.71207658e-02, 1.08615611e-01,\n",
    " 3.68004418e-01, 6.81332842e-01, 8.62665685e-01, 9.32805596e-01,\n",
    " 9.54712813e-01]\n",
    "x_tyler=range(10,140, 10)\n",
    "#plt.plot(x_tyler, ex_eff_tyler, '-', label='Extr. 3/4: MC (Tyler)')\n",
    "#plt.plot(x_tyler, meas_eff_tyler, '-', label='Meas. 3/4: MC (Tyler)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.hist(ar_skim[ar_skim['mc']==True]['trackIntercept'], bins=1000, range=(20000, 21000), histtype='step');\n",
    "plt.figure(figsize=(18, 6))  # Adjust the width and height as needed\n",
    "\n",
    "base_cuts = (abs(ar_skim[\"trackSlope\"]) < 1.5)\n",
    "\n",
    "#plt.hist(ar_skim[~ar_skim['mc'] & base_cuts]['trackIntercept'], bins=1000, range=(-1000, 0), histtype='step', density=True, label=\"Data\");\n",
    "#plt.hist(-1*ar_skim[ar_skim['mc'] & base_cuts]['trackIntercept']-1000-5, bins=1000, range=(-1000, 0), histtype='step', density=True, label=\"MC\");\n",
    "plt.hist(ar_skim[ar_skim['mc'] & base_cuts]['trackIntercept']+24, bins=1000, range=(-1000, 0), histtype='step', density=True, label=\"MC\");\n",
    "plt.legend()\n",
    "plt.xlabel(\"trackIntercept\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(ar_skim[(ar_skim['mc']==False)]['trackChi2NDF'], bins=1000, range=(0, 100), histtype='step', density=True, label=\"Data\");\n",
    "plt.hist(ar_skim[(ar_skim['mc']==True)]['trackChi2NDF'], bins=1000, range=(0, 100), histtype='step', density=True, label=\"MC\");\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"trackChi2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, histogram in enumerate(histogram_list[:-2]):\n",
    "    ncols = 3\n",
    "    ax_id = idx%ncols\n",
    "    if ax_id == 0:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(20, 5))\n",
    "\n",
    "    h = histogram[:, 3, \"trackChi2\", True]\n",
    "    mplhep.histplot(h, ax=axes[ax_id], label=\"MC, Events: %d\"%h.to_numpy(flow=True)[0].sum(), density=True, flow=\"sum\")\n",
    "\n",
    "    h = histogram[:, 3, \"trackChi2\", False]\n",
    "    mplhep.histplot(h, ax=axes[ax_id], label=\"Data, Events: %d\"%h.to_numpy(flow=True)[0].sum(), density=True, flow=\"sum\")\n",
    "\n",
    "#    h = histogram[:, 1, \"trackChi2\", False]\n",
    "#    hplot = mplhep.histplot(h, ax=axes[ax_id], label=\"Data <2/4, Events: %d\"%h.to_numpy(flow=True)[0].sum(), density=True, flow=\"sum\", yerr=False)\n",
    "    \n",
    "    axes[ax_id].set_xlabel(histogram.axes[0].label)\n",
    "    axes[ax_id].legend()\n",
    "#    axes[ax_id].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions before any cuts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Apply cuts\n",
    "ar_skim['nTestHits'] = ak.sum(ar_skim['PEsTestLayers'] > 10, axis=-1)\n",
    "ar_3l = ar_skim[cut_categories[4] & (ar_skim['nTestHits']<3) & (~ar_skim['mc'])]  # less than 3 hits\n",
    "ar_4e = ar_skim[cut_categories[4] & (ar_skim['nTestHits']==4) & (~ar_skim['mc'])] # equal to 4 hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ar_skim_fields = ar_skim.fields.copy()\n",
    "ar_skim_fields.remove('PEsTestLayers')\n",
    "#ar_skim_fields.remove('PEsTrigLayers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "ak.to_dataframe(ar_3l[ar_skim_fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eff = len(ar_3l)/len(ar_4e)\n",
    "print(\"Efficiency at 10 PE: %.2e\"%eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Mu2eCRV]",
   "language": "python",
   "name": "conda-env-.conda-Mu2eCRV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
